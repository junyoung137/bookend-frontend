/**
 * í”„ë¡ íŠ¸ì—”ë“œ HuggingFace API Route
 * í”¼ë“œë°± ì—†ëŠ” ì‚¬ìš©ìì˜ ê¸°ë³¸ êµì • ì²˜ë¦¬
 */

import { NextRequest, NextResponse } from "next/server";

interface GenerateRequest {
  prompt: string;
  parameters?: {
    temperature?: number;
    top_p?: number;
    max_tokens?: number;
  };
}

export async function POST(request: NextRequest) {
  try {
    const body: GenerateRequest = await request.json();
    const { prompt, parameters } = body;

    const apiKey = process.env.HUGGINGFACE_API_KEY;
    if (!apiKey) {
      return NextResponse.json(
        { error: "âŒ HuggingFace API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 500 }
      );
    }

    const model =
      process.env.NEXT_PUBLIC_LLM_MODEL ||
      "meta-llama/Llama-3.2-3B-Instruct";

    // âœ… HuggingFace Router API (ìµœì‹ )
    const url = "https://router.huggingface.co/v1/chat/completions";
    
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 60000); // 60ì´ˆ

    console.log("ğŸš€ HuggingFace API ìš”ì²­:", { 
      url, 
      model, 
      promptLength: prompt.length 
    });

    const response = await fetch(url, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: model,
        messages: [
          {
            role: "user",
            content: prompt,
          },
        ],
        temperature: parameters?.temperature ?? 0.7,
        top_p: parameters?.top_p ?? 0.9,
        max_tokens: parameters?.max_tokens ?? 512,
        stream: false,
      }),
      signal: controller.signal,
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      console.error("âŒ HuggingFace API Error:", {
        status: response.status,
        statusText: response.statusText,
        error: errorData,
      });

      // âœ… 503: ëª¨ë¸ ë¡œë”© ì¤‘
      if (response.status === 503) {
        return NextResponse.json(
          {
            error: "ëª¨ë¸ì´ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤. 20ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            retryable: true,
          },
          { status: 503 }
        );
      }

      // âœ… 404: ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ ë¬¸ì œ
      if (response.status === 404) {
        return NextResponse.json(
          {
            error: "ëª¨ë¸ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HuggingFaceì—ì„œ ëª¨ë¸ ë¼ì´ì„¼ìŠ¤ë¥¼ ìŠ¹ì¸í•´ì£¼ì„¸ìš”.",
            model: model,
          },
          { status: 404 }
        );
      }

      return NextResponse.json(
        { error: `API Error ${response.status}: ${response.statusText}` },
        { status: response.status }
      );
    }

    const data = await response.json();
    console.log("âœ… HuggingFace API ì‘ë‹µ ì„±ê³µ");

    // âœ… OpenAI í˜¸í™˜ ì‘ë‹µ íŒŒì‹±
    let generatedText = "";
    if (data.choices && data.choices.length > 0) {
      generatedText = data.choices[0].message?.content || "";
    } else if (data.generated_text) {
      generatedText = data.generated_text;
    } else {
      generatedText = JSON.stringify(data);
    }

    return NextResponse.json({
      success: true,
      data: {
        generated_text: generatedText,
      },
    });

  } catch (error: any) {
    console.error("âŒ API Route Error:", error);

    // âœ… Timeout ì—ëŸ¬
    if (error.name === "AbortError") {
      return NextResponse.json(
        { error: "ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”." },
        { status: 504 }
      );
    }

    return NextResponse.json(
      { error: error.message || "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." },
      { status: 500 }
    );
  }
}
